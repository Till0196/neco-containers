diff --git a/bpf/bpf_lxc.c b/bpf/bpf_lxc.c
index 8a000b52f0..38be9f1328 100644
--- a/bpf/bpf_lxc.c
+++ b/bpf/bpf_lxc.c
@@ -280,19 +280,21 @@ ct_recreate6:
 		policy_mark_skip(ctx);
 
 #ifdef ENABLE_NODEPORT
-		/* See comment in handle_ipv4_from_lxc(). */
-		if (ct_state.node_port) {
-			ctx->tc_index |= TC_INDEX_F_SKIP_RECIRCULATION;
-			ep_tail_call(ctx, CILIUM_CALL_IPV6_NODEPORT_REVNAT);
-			return DROP_MISSED_TAIL_CALL;
-		}
 # ifdef ENABLE_DSR
 		if (ct_state.dsr) {
 			ret = xlate_dsr_v6(ctx, tuple, l4_off);
 			if (ret != 0)
 				return ret;
-		}
+		} else
 # endif /* ENABLE_DSR */
+		/* See comment in handle_ipv4_from_lxc(). */
+		if (ct_state.node_port) {
+			send_trace_notify(ctx, TRACE_TO_NETWORK, SECLABEL,
+							  *dst_id, 0, 0, ret, monitor);
+			ctx->tc_index |= TC_INDEX_F_SKIP_RECIRCULATION;
+			ep_tail_call(ctx, CILIUM_CALL_IPV6_NODEPORT_REVNAT);
+			return DROP_MISSED_TAIL_CALL;
+		}
 #endif /* ENABLE_NODEPORT */
 		if (ct_state.rev_nat_index) {
 			ret = lb6_rev_nat(ctx, l4_off, &csum_off,
@@ -713,22 +715,25 @@ ct_recreate4:
 		policy_mark_skip(ctx);
 
 #ifdef ENABLE_NODEPORT
+# ifdef ENABLE_DSR
+		if (ct_state.dsr) {
+			ret = xlate_dsr_v4(ctx, &tuple, l4_off, has_l4_header);
+			if (ret != 0)
+				return ret;
+		} else
+# endif /* ENABLE_DSR */
 		/* This handles reply traffic for the case where the nodeport EP
-		 * is local to the node. We'll redirect to bpf_host egress to
-		 * perform the reverse DNAT.
+		 * is local to the node. We'll do the tail call to perform
+		 * the reverse DNAT.
 		 */
 		if (ct_state.node_port) {
+			send_trace_notify(ctx, TRACE_TO_NETWORK, SECLABEL,
+							  *dst_id, 0, 0, ct_ret, monitor);
 			ctx->tc_index |= TC_INDEX_F_SKIP_RECIRCULATION;
 			ep_tail_call(ctx, CILIUM_CALL_IPV4_NODEPORT_REVNAT);
 			return DROP_MISSED_TAIL_CALL;
 		}
-# ifdef ENABLE_DSR
-		if (ct_state.dsr) {
-			ret = xlate_dsr_v4(ctx, &tuple, l4_off, has_l4_header);
-			if (ret != 0)
-				return ret;
-		}
-# endif /* ENABLE_DSR */
+
 #endif /* ENABLE_NODEPORT */
 
 		if (ct_state.rev_nat_index) {
@@ -1140,9 +1145,10 @@ ipv6_policy(struct __ctx_buff *ctx, int ifindex, __u32 src_label, __u8 *reason,
 					   verdict, policy_match_type, audited);
 	}
 
-#ifdef ENABLE_DSR
+#ifdef ENABLE_NODEPORT
 	if (ret == CT_NEW || ret == CT_REOPENED) {
 		bool dsr = false;
+# ifdef ENABLE_DSR
 		int ret2;
 
 		ret2 = handle_dsr_v6(ctx, &dsr);
@@ -1150,15 +1156,25 @@ ipv6_policy(struct __ctx_buff *ctx, int ifindex, __u32 src_label, __u8 *reason,
 			return ret2;
 
 		ct_state_new.dsr = dsr;
-		if (ret == CT_REOPENED)
+		if (ret == CT_REOPENED && ct_state.dsr != dsr)
 			ct_update6_dsr(get_ct_map6(&tuple), &tuple, dsr);
+# endif /* ENABLE_DSR */
+		if (!dsr) {
+			bool node_port =
+				ct_has_nodeport_egress_entry6(get_ct_map6(&tuple),
+							      &tuple);
+
+			ct_state_new.node_port = node_port;
+			if (ret == CT_REOPENED &&
+			    ct_state.node_port != node_port)
+				ct_update_nodeport(get_ct_map6(&tuple), &tuple,
+						   node_port);
+		}
 	}
-#endif /* ENABLE_DSR */
+#endif /* ENABLE_NODEPORT */
 
 	if (ret == CT_NEW) {
 		ct_state_new.src_sec_id = src_label;
-		ct_state_new.node_port = ct_state.node_port;
-		ct_state_new.ifindex = ct_state.ifindex;
 		ret = ct_create6(get_ct_map6(&tuple), &CT_MAP_ANY6, &tuple, ctx, CT_INGRESS,
 				 &ct_state_new, verdict > 0);
 		if (IS_ERR(ret))
@@ -1445,9 +1461,10 @@ ipv4_policy(struct __ctx_buff *ctx, int ifindex, __u32 src_label, __u8 *reason,
 skip_policy_enforcement:
 #endif /* ENABLE_PER_PACKET_LB && !DISABLE_LOOPBACK_LB */
 
-#ifdef ENABLE_DSR
+#ifdef ENABLE_NODEPORT
 	if (ret == CT_NEW || ret == CT_REOPENED) {
 		bool dsr = false;
+# ifdef ENABLE_DSR
 		int ret2;
 
 		ret2 = handle_dsr_v4(ctx, &dsr);
@@ -1455,15 +1472,25 @@ skip_policy_enforcement:
 			return ret2;
 
 		ct_state_new.dsr = dsr;
-		if (ret == CT_REOPENED)
+		if (ret == CT_REOPENED && ct_state.dsr != dsr)
 			ct_update4_dsr(get_ct_map4(&tuple), &tuple, dsr);
+# endif /* ENABLE_DSR */
+		if (!dsr) {
+			bool node_port =
+				ct_has_nodeport_egress_entry4(get_ct_map4(&tuple),
+							      &tuple);
+
+			ct_state_new.node_port = node_port;
+			if (ret == CT_REOPENED &&
+			    ct_state.node_port != node_port)
+				ct_update_nodeport(get_ct_map4(&tuple), &tuple,
+						   node_port);
+		}
 	}
-#endif /* ENABLE_DSR */
+#endif /* ENABLE_NODEPORT */
 
 	if (ret == CT_NEW) {
 		ct_state_new.src_sec_id = src_label;
-		ct_state_new.node_port = ct_state.node_port;
-		ct_state_new.ifindex = ct_state.ifindex;
 		ret = ct_create4(get_ct_map4(&tuple), &CT_MAP_ANY4, &tuple, ctx, CT_INGRESS,
 				 &ct_state_new, verdict > 0);
 		if (IS_ERR(ret))
diff --git a/bpf/lib/conntrack.h b/bpf/lib/conntrack.h
index 045d9e566b..09281c1b81 100644
--- a/bpf/lib/conntrack.h
+++ b/bpf/lib/conntrack.h
@@ -169,31 +169,6 @@ static __always_inline bool ct_entry_alive(const struct ct_entry *entry)
 	return !entry->rx_closing || !entry->tx_closing;
 }
 
-/* Helper for holding 2nd service entry alive in nodeport case. */
-static __always_inline bool __ct_entry_keep_alive(const void *map,
-						  const void *tuple)
-{
-	struct ct_entry *entry;
-
-	/* Lookup indicates to LRU that key/value is in use. */
-	entry = map_lookup_elem(map, tuple);
-	if (entry) {
-		if (entry->node_port) {
-#ifdef NEEDS_TIMEOUT
-			__u32 lifetime = (entry->seen_non_syn ?
-					  bpf_sec_to_mono(CT_SERVICE_LIFETIME_TCP) :
-					  bpf_sec_to_mono(CT_SERVICE_LIFETIME_NONTCP)) +
-					 bpf_mono_now();
-			WRITE_ONCE(entry->lifetime, lifetime);
-#endif
-			if (!ct_entry_alive(entry))
-				ct_reset_closing(entry);
-		}
-		return true;
-	}
-	return false;
-}
-
 static __always_inline __u8 __ct_lookup(const void *map, struct __ctx_buff *ctx,
 					const void *tuple, int action, int dir,
 					struct ct_state *ct_state,
@@ -1024,6 +999,61 @@ static __always_inline int ct_create4(const void *map_main,
 	}
 	return 0;
 }
+
+/* The function tries to determine whether the flow identified by the given
+ * CT_INGRESS tuple belongs to a NodePort traffic (i.e., outside client => N/S
+ * LB => local backend).
+ *
+ * When the client send the NodePort request, the NodePort BPF
+ * (nodeport_lb{4,6}()) creates the CT_EGRESS entry for the
+ * (saddr=client,daddr=backend) tuple. So, to derive whether the reply packet
+ * backend => client belongs to the LB flow we can query the CT_EGRESS entry.
+ */
+static __always_inline bool
+ct_has_nodeport_egress_entry4(const void *map,
+			      struct ipv4_ct_tuple *ingress_tuple)
+{
+	int prev_flags = ingress_tuple->flags;
+	struct ct_entry *entry;
+
+	ingress_tuple->flags = TUPLE_F_OUT;
+	entry = map_lookup_elem(map, ingress_tuple);
+	ingress_tuple->flags = prev_flags;
+
+	if (entry)
+		return entry->node_port;
+
+	return 0;
+}
+
+static __always_inline bool
+ct_has_nodeport_egress_entry6(const void *map,
+			      struct ipv6_ct_tuple *ingress_tuple)
+{
+	int prev_flags = ingress_tuple->flags;
+	struct ct_entry *entry;
+
+	ingress_tuple->flags = TUPLE_F_OUT;
+	entry = map_lookup_elem(map, ingress_tuple);
+	ingress_tuple->flags = prev_flags;
+
+	if (entry)
+		return entry->node_port;
+
+	return 0;
+}
+
+static __always_inline void
+ct_update_nodeport(const void *map, const void *tuple, const bool node_port)
+{
+	struct ct_entry *entry;
+
+	entry = map_lookup_elem(map, tuple);
+	if (!entry)
+		return;
+
+	entry->node_port = node_port;
+}
 #else /* !CONNTRACK */
 static __always_inline int
 ct_lookup6(const void *map __maybe_unused,
diff --git a/bpf/lib/nodeport.h b/bpf/lib/nodeport.h
index 85e23f90c8..93dbff8f4d 100644
--- a/bpf/lib/nodeport.h
+++ b/bpf/lib/nodeport.h
@@ -783,7 +783,7 @@ skip_service_lookup:
 				 CT_EGRESS, &ct_state, &monitor);
 		switch (ret) {
 		case CT_NEW:
-redo_all:
+redo:
 #ifdef PRESERVE_WORLD_ID
 			ct_state_new.src_sec_id = WORLD_ID;
 #else
@@ -795,37 +795,13 @@ redo_all:
 					 CT_EGRESS, &ct_state_new, false);
 			if (IS_ERR(ret))
 				return ret;
-			if (backend_local) {
-				ct_flip_tuple_dir6(&tuple);
-redo_local:
-				ct_state_new.rev_nat_index = 0;
-				ret = ct_create6(get_ct_map6(&tuple), NULL,
-						 &tuple, ctx, CT_INGRESS,
-						 &ct_state_new, false);
-				if (IS_ERR(ret))
-					return ret;
-			}
 			break;
 		case CT_REOPENED:
 		case CT_ESTABLISHED:
 		case CT_REPLY:
 			if (unlikely(ct_state.rev_nat_index !=
 				     svc->rev_nat_index))
-				goto redo_all;
-			if (backend_local) {
-				ct_flip_tuple_dir6(&tuple);
-				if (!__ct_entry_keep_alive(get_ct_map6(&tuple),
-							   &tuple)) {
-#ifdef PRESERVE_WORLD_ID
-					ct_state_new.src_sec_id = WORLD_ID;
-#else
-					ct_state_new.src_sec_id = SECLABEL;
-#endif /* PRESERVE_WORLD_ID */
-					ct_state_new.node_port = 1;
-					ct_state_new.ifindex = NATIVE_DEV_IFINDEX;
-					goto redo_local;
-				}
-			}
+				goto redo;
 			break;
 		default:
 			return DROP_UNKNOWN_CT;
@@ -1820,7 +1796,7 @@ skip_service_lookup:
 				 CT_EGRESS, &ct_state, &monitor);
 		switch (ret) {
 		case CT_NEW:
-redo_all:
+redo:
 #ifdef PRESERVE_WORLD_ID
 			ct_state_new.src_sec_id = WORLD_ID;
 #else
@@ -1832,19 +1808,6 @@ redo_all:
 					 CT_EGRESS, &ct_state_new, false);
 			if (IS_ERR(ret))
 				return ret;
-			if (backend_local) {
-				ct_flip_tuple_dir4(&tuple);
-redo_local:
-				/* Reset rev_nat_index, otherwise ipv4_policy()
-				 * in bpf_lxc will do invalid xlation.
-				 */
-				ct_state_new.rev_nat_index = 0;
-				ret = ct_create4(get_ct_map4(&tuple), NULL,
-						 &tuple, ctx, CT_INGRESS,
-						 &ct_state_new, false);
-				if (IS_ERR(ret))
-					return ret;
-			}
 			break;
 		case CT_REOPENED:
 		case CT_ESTABLISHED:
@@ -1854,21 +1817,7 @@ redo_local:
 			 */
 			if (unlikely(ct_state.rev_nat_index !=
 				     svc->rev_nat_index))
-				goto redo_all;
-			if (backend_local) {
-				ct_flip_tuple_dir4(&tuple);
-				if (!__ct_entry_keep_alive(get_ct_map4(&tuple),
-							   &tuple)) {
-#ifdef PRESERVE_WORLD_ID
-					ct_state_new.src_sec_id = WORLD_ID;
-#else
-					ct_state_new.src_sec_id = SECLABEL;
-#endif /* PRESERVE_WORLD_ID */
-					ct_state_new.node_port = 1;
-					ct_state_new.ifindex = NATIVE_DEV_IFINDEX;
-					goto redo_local;
-				}
-			}
+				goto redo;
 			break;
 		default:
 			return DROP_UNKNOWN_CT;
diff --git a/pkg/hubble/parser/threefour/parser.go b/pkg/hubble/parser/threefour/parser.go
index d38c2a5e30..1533784016 100644
--- a/pkg/hubble/parser/threefour/parser.go
+++ b/pkg/hubble/parser/threefour/parser.go
@@ -488,6 +488,10 @@ func decodeICMPv6(icmp *layers.ICMPv6) *pb.Layer4 {
 	}
 }
 
+func isReply(reason uint8) bool {
+	return reason & ^monitor.TraceReasonEncryptMask == monitor.TraceReasonCtReply
+}
+
 func decodeIsReply(tn *monitor.TraceNotify, pvn *monitor.PolicyVerdictNotify) *wrapperspb.BoolValue {
 	switch {
 	case tn != nil && monitorAPI.TraceObservationPointHasConnState(tn.ObsPoint):
@@ -495,7 +499,19 @@ func decodeIsReply(tn *monitor.TraceNotify, pvn *monitor.PolicyVerdictNotify) *w
 		// tracking state available. For certain trace point
 		// events, we do not know if it actually was a reply or not.
 		return &wrapperspb.BoolValue{
-			Value: tn.Reason & ^monitor.TraceReasonEncryptMask == monitor.TraceReasonCtReply,
+			Value: isReply(tn.Reason),
+		}
+	case tn != nil && tn.ObsPoint == monitorAPI.TraceToNetwork && tn.Reason > 0:
+		// FIXME(GH-18460): Even though the BPF programs emitting TraceToNetwork
+		// do have access to connection tracking state, that state is currently
+		// not exposed to userspace by all trace points. Therefore TraceToNetwork
+		// is currently excluded in TraceObservationPointHasConnState.
+		// However, the NodePort return path in handle_ipv4_from_lxc does
+		// populate tn.Reason, and always has with a non-zero value due it
+		// only being used for replies. Therefore, if tn.Reason is non-zero,
+		// we can safely determine if the traced packet was a reply or not.
+		return &wrapperspb.BoolValue{
+			Value: isReply(tn.Reason),
 		}
 	case pvn != nil && pvn.Verdict >= 0:
 		// Forwarded PolicyVerdictEvents are emitted for the first packet of
